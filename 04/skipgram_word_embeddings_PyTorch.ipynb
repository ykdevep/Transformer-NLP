{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef9552cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84977c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "text = \"The black cat sat on the couch and the brown dog slept on the rug\".lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b0cc122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'black', 'cat', 'sat', 'on', 'the', 'couch', 'and', 'the', 'brown', 'dog', 'slept', 'on', 'the', 'rug']\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d21723e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear vocabulario\n",
    "vocab = set(text)\n",
    "word2idx = {w: idx for idx, w in enumerate(vocab)}\n",
    "idx2word = {idx: w for w, idx in word2idx.items()}\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb1fc6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'and': 0, 'black': 1, 'on': 2, 'slept': 3, 'brown': 4, 'cat': 5, 'sat': 6, 'the': 7, 'rug': 8, 'couch': 9, 'dog': 10}\n"
     ]
    }
   ],
   "source": [
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad99fc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'and', 1: 'black', 2: 'on', 3: 'slept', 4: 'brown', 5: 'cat', 6: 'sat', 7: 'the', 8: 'rug', 9: 'couch', 10: 'dog'}\n"
     ]
    }
   ],
   "source": [
    "print(idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3267c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n"
     ]
    }
   ],
   "source": [
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f3686c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datos de entrenamiento (skip-gram con ventana de contexto 2)\n",
    "def generate_skipgram_data(text, window_size=2):\n",
    "    pairs = []\n",
    "    for i, target in enumerate(text):\n",
    "        for j in range(-window_size, window_size + 1):\n",
    "            if j == 0 or i + j < 0 or i + j >= len(text):\n",
    "                continue\n",
    "            context = text[i + j]\n",
    "            pairs.append((target, context))\n",
    "    return pairs\n",
    "\n",
    "pairs = generate_skipgram_data(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d92ea0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 'black'), ('the', 'cat'), ('black', 'the'), ('black', 'cat'), ('black', 'sat'), ('cat', 'the'), ('cat', 'black'), ('cat', 'sat'), ('cat', 'on'), ('sat', 'black'), ('sat', 'cat'), ('sat', 'on'), ('sat', 'the'), ('on', 'cat'), ('on', 'sat'), ('on', 'the'), ('on', 'couch'), ('the', 'sat'), ('the', 'on'), ('the', 'couch'), ('the', 'and'), ('couch', 'on'), ('couch', 'the'), ('couch', 'and'), ('couch', 'the'), ('and', 'the'), ('and', 'couch'), ('and', 'the'), ('and', 'brown'), ('the', 'couch'), ('the', 'and'), ('the', 'brown'), ('the', 'dog'), ('brown', 'and'), ('brown', 'the'), ('brown', 'dog'), ('brown', 'slept'), ('dog', 'the'), ('dog', 'brown'), ('dog', 'slept'), ('dog', 'on'), ('slept', 'brown'), ('slept', 'dog'), ('slept', 'on'), ('slept', 'the'), ('on', 'dog'), ('on', 'slept'), ('on', 'the'), ('on', 'rug'), ('the', 'slept'), ('the', 'on'), ('the', 'rug'), ('rug', 'on'), ('rug', 'the')]\n"
     ]
    }
   ],
   "source": [
    "print(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1440fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a Ã­ndices\n",
    "train_data = [(word2idx[target], word2idx[context]) for target, context in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81135748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7, 1), (7, 5), (1, 7), (1, 5), (1, 6), (5, 7), (5, 1), (5, 6), (5, 2), (6, 1), (6, 5), (6, 2), (6, 7), (2, 5), (2, 6), (2, 7), (2, 9), (7, 6), (7, 2), (7, 9), (7, 0), (9, 2), (9, 7), (9, 0), (9, 7), (0, 7), (0, 9), (0, 7), (0, 4), (7, 9), (7, 0), (7, 4), (7, 10), (4, 0), (4, 7), (4, 10), (4, 3), (10, 7), (10, 4), (10, 3), (10, 2), (3, 4), (3, 10), (3, 2), (3, 7), (2, 10), (2, 3), (2, 7), (2, 8), (7, 3), (7, 2), (7, 8), (8, 2), (8, 7)]\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4544bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo Skip-Gram\n",
    "class SkipGramModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.output = nn.Linear(embedding_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, input_word):\n",
    "        embed = self.embeddings(input_word)\n",
    "        out = self.output(embed)\n",
    "        return out\n",
    "\n",
    "embedding_dim = 15\n",
    "model = SkipGramModel(vocab_size, embedding_dim)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9d93b1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SkipGramModel(\n",
      "  (embeddings): Embedding(11, 15)\n",
      "  (output): Linear(in_features=15, out_features=11, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6e75f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 142.2775\n",
      "Epoch 10, Loss: 142.2472\n",
      "Epoch 20, Loss: 142.2176\n",
      "Epoch 30, Loss: 142.1879\n",
      "Epoch 40, Loss: 142.1582\n",
      "Epoch 50, Loss: 142.1286\n",
      "Epoch 60, Loss: 142.0990\n",
      "Epoch 70, Loss: 142.0694\n",
      "Epoch 80, Loss: 142.0399\n",
      "Epoch 90, Loss: 142.0104\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for input_idx, target_idx in train_data:\n",
    "        input_tensor = torch.tensor([input_idx], dtype=torch.long)\n",
    "        target_tensor = torch.tensor([target_idx], dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(input_tensor)\n",
    "        loss = loss_fn(output, target_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8853b4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de 'black': [[ 0.6081965  -0.27331546 -1.2913392  -0.15249166  1.9993314   0.8663557\n",
      "  -2.3744898   0.54114026 -1.1109648   2.085534    1.1988776   2.0892808\n",
      "  -0.1214344   1.9393797   0.85767335]]\n",
      "Embedding de 'brown': [[-0.2402617   2.252105    1.9834756   0.45905763 -0.96503824 -0.57575446\n",
      "   2.0313282  -1.4046042   0.6116017   1.3756244  -1.3545616   1.3084308\n",
      "   0.6670409  -1.4410648  -0.3797013 ]]\n"
     ]
    }
   ],
   "source": [
    "# Obtener embeddings de \"black\" y \"brown\"\n",
    "black_idx = word2idx[\"black\"]\n",
    "brown_idx = word2idx[\"brown\"]\n",
    "\n",
    "black_embedding = model.embeddings(torch.tensor([black_idx])).detach().numpy()\n",
    "brown_embedding = model.embeddings(torch.tensor([brown_idx])).detach().numpy()\n",
    "\n",
    "print(f\"Embedding de 'black': {black_embedding}\")\n",
    "print(f\"Embedding de 'brown': {brown_embedding}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e5aae01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como skipgram_model_15d.pth\n",
      "Modelo cargado desde skipgram_model_15d.pth\n"
     ]
    }
   ],
   "source": [
    "#  Guardar modelo entrenado\n",
    "torch.save(model.state_dict(), f\"skipgram_model_{embedding_dim}d.pth\")\n",
    "print(f\"Modelo guardado como skipgram_model_{embedding_dim}d.pth\")\n",
    "\n",
    "\n",
    "# Cargar modelo guardado\n",
    "loaded_model = SkipGramModel(vocab_size=vocab_size, embedding_dim=embedding_dim)\n",
    "loaded_model.load_state_dict(torch.load(f\"skipgram_model_{embedding_dim}d.pth\"))\n",
    "loaded_model.eval()\n",
    "print(f\"Modelo cargado desde skipgram_model_{embedding_dim}d.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "165ba9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding de 'black': [[ 0.6081965  -0.27331546 -1.2913392  -0.15249166  1.9993314   0.8663557\n",
      "  -2.3744898   0.54114026 -1.1109648   2.085534    1.1988776   2.0892808\n",
      "  -0.1214344   1.9393797   0.85767335]]\n",
      "Embedding de 'brown': [[-0.2402617   2.252105    1.9834756   0.45905763 -0.96503824 -0.57575446\n",
      "   2.0313282  -1.4046042   0.6116017   1.3756244  -1.3545616   1.3084308\n",
      "   0.6670409  -1.4410648  -0.3797013 ]]\n"
     ]
    }
   ],
   "source": [
    "# Obtener embeddings de \"black\" y \"brown\"\n",
    "black_idx = word2idx[\"black\"]\n",
    "brown_idx = word2idx[\"brown\"]\n",
    "\n",
    "black_embedding = loaded_model.embeddings(torch.tensor([black_idx])).detach().numpy()\n",
    "brown_embedding = loaded_model.embeddings(torch.tensor([brown_idx])).detach().numpy()\n",
    "\n",
    "print(f\"Embedding de 'black': {black_embedding}\")\n",
    "print(f\"Embedding de 'brown': {brown_embedding}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
